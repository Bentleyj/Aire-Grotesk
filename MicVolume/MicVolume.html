<html>
	<head>
		<title>Mic Volume</title>
		<style>
		body {
		  background-color: white;
		  color: black;
		  margin: 0;
		  padding: 1em;
		  text-align: center;
		}

		#value {
		  color: black;
		  font-size: 60px;
		}

		#meter {
		  margin-top:60px;
		}


		button {
		  color: black;
		  padding: 4px 16px;
		}

		.p {
		  padding: 0;
		  text-align: center;
		}



		@font-face {
		  font-family:'Decovar Alpha Regular24';      
		  src:url('https://www.axis-praxis.org/fonts/webfonts/DecovarAlpha-VF.woff2');
		  font-variation-settings: "BLDA" 0, "TRMD" 0, "TRMC" 0, "SKLD" 0, "TRML" 0, "SKLA" 0, "TRMF" 0, "TRMK" 0, "BLDB" 0, "WMX2" 0, "TRMB" 0, "TRMA" 1000, "SKLB" 0, "TRMG" 0, "TRME" 0;
		}


		#para1 {
		  font-size:200px;
		  color: black;
		  font-family: "Decovar Alpha Regular24";
		  font-variation-settings: "SKLD" 0, "SKLA" 0;
		  font-stretch: 500%;
		  margin: 0;
		}
		</style>
	</head>
	<body>
		<canvas id="meter" width="900" height="150"></canvas>
		<p id="para1">EXPLODE!</p>
		<span id="value"><span>
		<script>
			var text = document.getElementById("para1");
			var value = document.getElementById("value");

			function createAudioMeter(audioContext,clipLevel,averaging,clipLag) {
				var processor = audioContext.createScriptProcessor(512);
				processor.onaudioprocess = volumeAudioProcess;
				processor.clipping = false;
				processor.lastClip = 0;
				processor.volume = 0;
				processor.clipLevel = clipLevel || 0.98;
				processor.averaging = averaging || 0.95;
				processor.clipLag = clipLag || 750;

				// this will have no effect, since we don't copy the input to the output,
				// but works around a current Chrome bug.
				processor.connect(audioContext.destination);

				processor.checkClipping =
					function(){
						if (!this.clipping)
							return false;
						if ((this.lastClip + this.clipLag) < window.performance.now())
							this.clipping = false;
						return this.clipping;
					};

				processor.shutdown =
					function(){
						this.disconnect();
						this.onaudioprocess = null;
					};

				return processor;
			}

			function volumeAudioProcess( event ) {
				var buf = event.inputBuffer.getChannelData(0);
			    var bufLength = buf.length;
				var sum = 0;
			    var x;

				// Do a root-mean-square on the samples: sum up the squares...
			    for (var i=0; i<bufLength; i++) {
			    	x = buf[i];
			    	if (Math.abs(x)>=this.clipLevel) {
			    		this.clipping = true;
			    		this.lastClip = window.performance.now();
			    	}
			    	sum += x * x;
			    }

			    // ... then take the square root of the sum.
			    var rms =  Math.sqrt(sum / bufLength);

			    // Now smooth this out with the averaging factor applied
			    // to the previous sample - take the max here because we
			    // want "fast attack, slow release."
			    this.volume = Math.max(rms, this.volume*this.averaging);
			}

			var audioContext = null;
			var meter = null;
			var canvasContext = null;
			var WIDTH=900;
			var HEIGHT=150;
			var rafID = null;

			window.onload = function() {

			    // grab our canvas
				canvasContext = document.getElementById( "meter" ).getContext("2d");
				
			    // monkeypatch Web Audio
			    window.AudioContext = window.AudioContext || window.webkitAudioContext;
				
			    // grab an audio context
			    audioContext = new AudioContext();

			    // Attempt to get audio input
			    try {
			        // monkeypatch getUserMedia
			        navigator.getUserMedia = 
			        	navigator.getUserMedia ||
			        	navigator.webkitGetUserMedia ||
			        	navigator.mozGetUserMedia;

			        // ask for an audio input
			        navigator.getUserMedia(
			        {
			            "audio": {
			                "mandatory": {
			                    "googEchoCancellation": "false",
			                    "googAutoGainControl": "false",
			                    "googNoiseSuppression": "false",
			                    "googHighpassFilter": "false"
			                },
			                "optional": []
			            },
			        }, onMicrophoneGranted, onMicrophoneDenied);
			    } catch (e) {
			        alert('getUserMedia threw exception :' + e);
			    }

			}

			function onMicrophoneDenied() {
			    alert('Stream generation failed.');
			}

			var mediaStreamSource = null;

			function onMicrophoneGranted(stream) {
			    // Create an AudioNode from the stream.
			    mediaStreamSource = audioContext.createMediaStreamSource(stream);

			    // Create a new volume meter and connect it.
			    meter = createAudioMeter(audioContext);
			    mediaStreamSource.connect(meter);

			    // kick off the visual updating
			    onLevelChange();
			}

			function onLevelChange( time ) {
			    // clear the background
			    canvasContext.clearRect(0,0,WIDTH,HEIGHT);

			    // check if we're currently clipping
			    if (meter.checkClipping())
			        canvasContext.fillStyle = "red";
			    else
			        canvasContext.fillStyle = "green";

			 

			    // draw a bar based on the current volume
			  
			 if (meter.volume > 0) {    
			    var newVol = 0 + meter.volume * 500;
			    var volLength = meter.volume * 900 * 3;
			     //var volSize = 150 + meter.volume * 300;
			    console.log(volLength);
			    var skld = newVol * 10;
			   var skla = newVol * 10;
			   var wmx2 = newVol * 10
			   var settings = "font-variation-settings: 'SKLD' " + skld + ", 'BLDB' " + skld + ", 'WMX2' " + wmx2 + ";" ;
					text.setAttribute("style", ('font-variation-settings', settings));
			    //text.style.fontSize = volSize + "px";
			   value.innerHTML = Math.round((0 + meter.volume * 100)) + "%";
			    
			    canvasContext.fillRect(0, 0, volLength, HEIGHT);
			 }   

			    // set up the next visual callback
			    rafID = window.requestAnimationFrame( onLevelChange );
			}

		</script>
	</body>
</html>