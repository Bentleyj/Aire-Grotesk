<html>
	<head>
		<title>Mic Volume</title>
		<style>
		body {
		  background-color: black;
		  color: white;
		  margin: 0;
		  padding: 1em;
		  text-align: center;
		  width: 100%;
    	  height: 100%;
    	  padding: 0;
    	  position: relative;
		}

		.contents {
			position: absolute;
  			top: 50%;
  			left: 50%;
  			transform: translate(-50%, -50%);
		}

		#value {
		  color: white;
		  font-size: 60px;
		  font-family: "Zeitung Pro Regular";
		}

		#meter {
		  margin-top:60px;
		}


		button {
		  color: black;
		  padding: 4px 16px;
		}

		.p {
		  padding: 0;
		  text-align: center;
		}


		@font-face {
		  font-family:'Zeitung Pro Regular'; 
		  src:url('https://www.axis-praxis.org/fonts/webfonts/ZeitungProBeta.woff2');
		  font-stretch: 1% 500%;
		  font-weight: 1 1000;
		  font-stretch: 1% 500%;
		}


		#para1 {
		  font-size:200px;
		  color: bwhite;
		  font-family: "Zeitung Pro Regular";
		  font-stretch: 500%;
		  margin: 0;
		}

		</style>
	</head>
	<body>
		<div class="contents">
		<canvas id="meter" width="900" height="150"></canvas>
		<p id="para1">VOLUME!</p>
		<span id="value"></span>
		<script>
		var text = document.getElementById("para1");
		var value = document.getElementById("value");
		var vol = 0;

		function createAudioMeter(audioContext,clipLevel,averaging,clipLag) {
			var processor = audioContext.createScriptProcessor(512);
			processor.onaudioprocess = volumeAudioProcess;
			processor.clipping = false;
			processor.lastClip = 0;
			processor.volume = 0;
			processor.clipLevel = clipLevel || 0.98;
			processor.averaging = averaging || 0.95;
			processor.clipLag = clipLag || 750;

			// this will have no effect, since we don't copy the input to the output,
			// but works around a current Chrome bug.
			processor.connect(audioContext.destination);

			processor.checkClipping =
				function(){
					if (!this.clipping)
						return false;
					if ((this.lastClip + this.clipLag) < window.performance.now())
						this.clipping = false;
					return this.clipping;
				};

			processor.shutdown =
				function(){
					this.disconnect();
					this.onaudioprocess = null;
				};

			return processor;
		}

		function volumeAudioProcess( event ) {
			var buf = event.inputBuffer.getChannelData(0);
		    var bufLength = buf.length;
			var sum = 0;
		    var x;

			// Do a root-mean-square on the samples: sum up the squares...
		    for (var i=0; i<bufLength; i++) {
		    	x = buf[i];
		    	if (Math.abs(x)>=this.clipLevel) {
		    		this.clipping = true;
		    		this.lastClip = window.performance.now();
		    	}
		    	sum += x * x;
		    }

		    // ... then take the square root of the sum.
		    var rms =  Math.sqrt(sum / bufLength);

		    // Now smooth this out with the averaging factor applied
		    // to the previous sample - take the max here because we
		    // want "fast attack, slow release."
		    this.volume = Math.max(rms, this.volume*this.averaging);
		}

		var audioContext = null;
		var meter = null;
		var canvasContext = null;
		var WIDTH=900;
		var HEIGHT=150;
		var rafID = null;

		window.onload = function() {

		    // grab our canvas
			canvasContext = document.getElementById( "meter" ).getContext("2d");
			
		    // monkeypatch Web Audio
		    window.AudioContext = window.AudioContext || window.webkitAudioContext;
			
		    // grab an audio context
		    audioContext = new AudioContext();

		    // Attempt to get audio input
		    try {
		        // monkeypatch getUserMedia
		        navigator.getUserMedia = 
		        	navigator.getUserMedia ||
		        	navigator.webkitGetUserMedia ||
		        	navigator.mozGetUserMedia;

		        // ask for an audio input
		        navigator.getUserMedia(
		        {
		            "audio": {
		                "mandatory": {
		                    "googEchoCancellation": "false",
		                    "googAutoGainControl": "false",
		                    "googNoiseSuppression": "false",
		                    "googHighpassFilter": "false"
		                },
		                "optional": []
		            },
		        }, onMicrophoneGranted, onMicrophoneDenied);
		    } catch (e) {
		        alert('getUserMedia threw exception :' + e);
		    }

		}

		function onMicrophoneDenied() {
		    alert('Stream generation failed.');
		}

		var mediaStreamSource = null;

		function onMicrophoneGranted(stream) {
		    // Create an AudioNode from the stream.
		    mediaStreamSource = audioContext.createMediaStreamSource(stream);

		    // Create a new volume meter and connect it.
		    meter = createAudioMeter(audioContext);
		    mediaStreamSource.connect(meter);

		    // kick off the visual updating
		    onLevelChange();
		}

		function lerp(a, b, p) {
			var dist = b - a;
			var s = p * dist;
			return a + s;
		}

		function avg(a) {
			var t = 0;
			for(var i = 0; i < a.length; i++) {
				t += a[i];
			}
			return t /= a.length;
		}

		function stdev(a) {
			var avgA = avg(a);
			var total = 0;
			for(var i = 0; i < a.length; i++) {
				var t = a[i] - avgA;
				t = t*t;
				total += t;
			}
			total /= a.length;
			total = Math.sqrt(total);
			return total;
		}

		function onLevelChange( time ) {
		    // clear the background
		    canvasContext.clearRect(0,0,WIDTH,HEIGHT);

		    // check if we're currently clipping
		    if (meter.checkClipping())
		        canvasContext.fillStyle = "red";
		    else
		        canvasContext.fillStyle = "green";

		 

		    // draw a bar based on the current volume
		  
		 if (meter.volume > 0) {    
		    var newVol = meter.volume * 500;

		    vol = lerp(vol, newVol, 0.1);

		    var volLength = vol * 5.4;
		    text.style.fontWeight = vol * 9;

		   	value.innerHTML = Math.round((0 + meter.volume * 100)) + "%";
		    
		    canvasContext.fillRect(0, 0, volLength, HEIGHT);
		 }   

		    // set up the next visual callback
		    rafID = window.requestAnimationFrame( onLevelChange );
		}


		</script>
		</div>
	</body>
</html>